{
  super(name,props);
  this.baseJobConf=baseJobConf;
  this.mapperClass=Utils.notNull(mapperClass);
  this.inputFormatClass=Utils.notNull(inputFormatClass);
  this.inputPath=inputPath;
  this.cluster=Utils.notNull(cluster);
  this.storeDef=Utils.notNull(storeDef);
  this.tempDir=tempDir;
  this.outputDir=Utils.notNull(outputDir);
  this.checkSumType=checkSumType;
  this.saveKeys=saveKeys;
  this.reducerPerBucket=reducerPerBucket;
  this.chunkSizeBytes=chunkSizeBytes;
  this.numChunksOverride=numChunksOverride;
  this.isAvro=isAvro;
  this.minNumberOfRecords=minNumberOfRecords == null ? 1 : minNumberOfRecords;
  this.buildPrimaryReplicasOnly=buildPrimaryReplicasOnly;
  if (numChunksOverride <= 0) {
    logger.info("HadoopStoreBuilder constructed with numChunksOverride <= 0, thus relying chunk size.");
    if (chunkSizeBytes > MAX_CHUNK_SIZE || chunkSizeBytes < MIN_CHUNK_SIZE) {
      throw new VoldemortException("Invalid chunk size, chunk size must be in the range " + MIN_CHUNK_SIZE + "..."+ MAX_CHUNK_SIZE);
    }
  }
 else {
    logger.info("HadoopStoreBuilder constructed with numChunksOverride > 0, thus ignoring chunk size.");
  }
}
