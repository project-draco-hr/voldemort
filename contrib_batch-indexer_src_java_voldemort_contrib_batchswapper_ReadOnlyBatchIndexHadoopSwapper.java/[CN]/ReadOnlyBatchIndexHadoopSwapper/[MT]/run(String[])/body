{
  JobConf conf=new JobConf(ReadOnlyBatchIndexHadoopSwapper.class);
  configure(conf);
  Cluster cluster=null;
  try {
    cluster=ContribUtils.getVoldemortClusterDetails(conf.get("voldemort.cluster.local.filePath"));
    conf.setNumReduceTasks(0);
    conf.setInputFormat(NonSplitableDummyFileInputFormat.class);
    conf.setMapperClass(SwapperMapper.class);
    String storeName=conf.get("voldemort.store.name");
    moveMetaDatatoHDFS(conf,new Path(conf.get("voldemort.cluster.local.filePath")));
    FileInputFormat.setInputPaths(conf,new Path(conf.get("source.HDFS.path")));
    FileOutputFormat.setOutputPath(conf,new Path(conf.get("destination.remote.path")));
    JobClient.runJob(conf);
    for (    Node node : cluster.getNodes()) {
      SwapperUtils.doSwap(storeName,node,conf.get("destination.remote.path"));
    }
  }
 catch (  Exception e) {
    logger.error("Failed to read Voldemort cluster details",e);
    throw new RuntimeException("",e);
  }
  return 0;
}
