{
  logger.info("Building store " + storeDefinition.getName() + " for "+ cluster.getNumberOfPartitions()+ " partitions with "+ numChunks+ " chunks per partitions and version "+ type);
  int numNodes=cluster.getNumberOfNodes();
  DataOutputStream[][] indexes=new DataOutputStream[numNodes][];
  DataOutputStream[][] datas=new DataOutputStream[numNodes][];
  int[][] positions=new int[numNodes][];
  int[] partitionIdToChunkOffset=new int[cluster.getNumberOfPartitions()];
  int[] partitionIdToNodeId=new int[cluster.getNumberOfPartitions()];
  for (  Node node : cluster.getNodes()) {
    int nodeId=node.getId();
    indexes[nodeId]=new DataOutputStream[node.getNumberOfPartitions() * numChunks];
    datas[nodeId]=new DataOutputStream[node.getNumberOfPartitions() * numChunks];
    positions[nodeId]=new int[node.getNumberOfPartitions() * numChunks];
    File nodeDir=new File(outputDir,"node-" + Integer.toString(nodeId));
    nodeDir.mkdirs();
    BufferedWriter writer=new BufferedWriter(new FileWriter(new File(nodeDir,".metadata")));
    ReadOnlyStorageMetadata metadata=new ReadOnlyStorageMetadata();
    metadata.add(ReadOnlyStorageMetadata.FORMAT,type.getCode());
    writer.write(metadata.toJsonString());
    writer.close();
    int globalChunk=0;
    for (    Integer partition : node.getPartitionIds()) {
      partitionIdToChunkOffset[partition]=globalChunk;
      partitionIdToNodeId[partition]=node.getId();
      for (int chunk=0; chunk < numChunks; chunk++) {
        File indexFile=new File(nodeDir,Integer.toString(partition) + "_" + Integer.toString(chunk)+ ".index");
        File dataFile=new File(nodeDir,Integer.toString(partition) + "_" + Integer.toString(chunk)+ ".data");
        positions[nodeId][globalChunk]=0;
        indexes[nodeId][globalChunk]=new DataOutputStream(new BufferedOutputStream(new FileOutputStream(indexFile),ioBufferSize));
        datas[nodeId][globalChunk]=new DataOutputStream(new BufferedOutputStream(new FileOutputStream(dataFile),ioBufferSize));
        globalChunk++;
      }
    }
  }
  logger.info("Reading items...");
  int count=0;
  ExternalSorter<KeyValuePair> sorter=new ExternalSorter<KeyValuePair>(new KeyValuePairSerializer(),new KeyMd5Comparator(),internalSortSize,tempDir.getAbsolutePath(),ioBufferSize,numThreads,gzipIntermediate);
  JsonObjectIterator iter=new JsonObjectIterator(reader,storeDefinition);
  for (  KeyValuePair pair : sorter.sorted(iter)) {
    byte[] keyMd5=pair.getKeyMd5();
    List<Integer> partitionIds=this.routingStrategy.getPartitionList(pair.getKey());
    for (    Integer partitionId : partitionIds) {
      int localChunkId=ReadOnlyUtils.chunk(keyMd5,numChunks);
      int chunk=localChunkId + partitionIdToChunkOffset[partitionId];
      int nodeId=partitionIdToNodeId[partitionId];
switch (type) {
case READONLY_V1:
        datas[nodeId][chunk].writeInt(pair.getValue().length);
      datas[nodeId][chunk].write(pair.getValue());
    indexes[nodeId][chunk].write(keyMd5);
  indexes[nodeId][chunk].writeInt(positions[nodeId][chunk]);
positions[nodeId][chunk]+=pair.getValue().length + 4;
break;
case READONLY_V2:
datas[nodeId][chunk].writeInt(pair.getKey().length);
datas[nodeId][chunk].write(pair.getKey());
datas[nodeId][chunk].writeInt(pair.getValue().length);
datas[nodeId][chunk].write(pair.getValue());
indexes[nodeId][chunk].write(keyMd5);
indexes[nodeId][chunk].writeInt(positions[nodeId][chunk]);
positions[nodeId][chunk]+=pair.getKey().length + pair.getValue().length + 4+ 4;
break;
default :
throw new VoldemortException("Cannot support building readonly storage format " + type);
}
checkOverFlow(chunk,positions[nodeId][chunk]);
}
count++;
}
logger.info(count + " items read.");
logger.info("Closing all store files.");
for (Node node : cluster.getNodes()) {
for (int chunk=0; chunk < numChunks * node.getNumberOfPartitions(); chunk++) {
indexes[node.getId()][chunk].close();
datas[node.getId()][chunk].close();
}
}
}
