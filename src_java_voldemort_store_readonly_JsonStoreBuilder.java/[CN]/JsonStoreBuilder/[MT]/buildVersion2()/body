{
  logger.info("Building store " + storeDefinition.getName() + " for "+ cluster.getNumberOfPartitions()+ " partitions with "+ numChunks+ " chunks per partitions and type "+ ReadOnlyStorageFormat.READONLY_V2);
  int numNodes=cluster.getNumberOfNodes();
  DataOutputStream[][] indexes=new DataOutputStream[numNodes][];
  DataOutputStream[][] datas=new DataOutputStream[numNodes][];
  int[][] positions=new int[numNodes][];
  int[] partitionIdToChunkOffset=new int[cluster.getNumberOfPartitions()];
  int[] partitionIdToNodeId=new int[cluster.getNumberOfPartitions()];
  for (  Node node : cluster.getNodes()) {
    int nodeId=node.getId();
    indexes[nodeId]=new DataOutputStream[node.getNumberOfPartitions() * numChunks];
    datas[nodeId]=new DataOutputStream[node.getNumberOfPartitions() * numChunks];
    positions[nodeId]=new int[node.getNumberOfPartitions() * numChunks];
    File nodeDir=new File(outputDir,"node-" + Integer.toString(nodeId));
    nodeDir.mkdirs();
    BufferedWriter writer=new BufferedWriter(new FileWriter(new File(nodeDir,".metadata")));
    ReadOnlyStorageMetadata metadata=new ReadOnlyStorageMetadata();
    metadata.add(ReadOnlyStorageMetadata.FORMAT,ReadOnlyStorageFormat.READONLY_V2.getCode());
    writer.write(metadata.toJsonString());
    writer.close();
    int globalChunk=0;
    for (    Integer partition : node.getPartitionIds()) {
      partitionIdToChunkOffset[partition]=globalChunk;
      partitionIdToNodeId[partition]=node.getId();
      for (int chunk=0; chunk < numChunks; chunk++) {
        File indexFile=new File(nodeDir,Integer.toString(partition) + "_" + Integer.toString(chunk)+ ".index");
        File dataFile=new File(nodeDir,Integer.toString(partition) + "_" + Integer.toString(chunk)+ ".data");
        positions[nodeId][globalChunk]=0;
        indexes[nodeId][globalChunk]=new DataOutputStream(new BufferedOutputStream(new FileOutputStream(indexFile),ioBufferSize));
        datas[nodeId][globalChunk]=new DataOutputStream(new BufferedOutputStream(new FileOutputStream(dataFile),ioBufferSize));
        globalChunk++;
      }
    }
  }
  logger.info("Reading items...");
  int count=0;
  ExternalSorter<KeyValuePair> sorter=new ExternalSorter<KeyValuePair>(new KeyValuePairSerializer(),new KeyMd5Comparator(),internalSortSize,tempDir.getAbsolutePath(),ioBufferSize,numThreads,gzipIntermediate);
  JsonObjectIterator iter=new JsonObjectIterator(reader,storeDefinition);
  ListMultimap<Pair<Integer,Integer>,KeyValuePair> buckets=ArrayListMultimap.create();
  for (  KeyValuePair pair : sorter.sorted(iter)) {
    List<Integer> partitionIds=this.routingStrategy.getPartitionList(pair.getKey());
    for (    Integer partitionId : partitionIds) {
      int localChunkId=ReadOnlyUtils.chunk(pair.getKeyMd5(),numChunks);
      int chunk=localChunkId + partitionIdToChunkOffset[partitionId];
      int nodeId=partitionIdToNodeId[partitionId];
      buckets.put(Pair.create(nodeId,chunk),pair);
    }
    count++;
  }
  logger.info(count + " items read.");
  for (  Pair<Integer,Integer> bucket : buckets.keySet()) {
    List<KeyValuePair> keyValuePairs=buckets.get(bucket);
    int nodeId=bucket.getFirst();
    int chunk=bucket.getSecond();
    int index=0;
    KeyValuePair prevPair=null, currentPair=null;
    while (currentPair != null || index < keyValuePairs.size()) {
      if (currentPair == null)       currentPair=keyValuePairs.get(index);
      indexes[nodeId][chunk].write(ByteUtils.copy(currentPair.keyMd5,0,2 * ByteUtils.SIZE_OF_INT));
      indexes[nodeId][chunk].writeInt(positions[nodeId][chunk]);
      int tuples=0;
      ByteArrayOutputStream stream=new ByteArrayOutputStream();
      DataOutputStream valueStream=new DataOutputStream(stream);
      do {
        valueStream.writeInt(currentPair.getKey().length);
        valueStream.write(currentPair.getKey());
        valueStream.writeInt(currentPair.getValue().length);
        valueStream.write(currentPair.getValue());
        index++;
        tuples++;
        if (index < keyValuePairs.size()) {
          prevPair=currentPair;
          currentPair=keyValuePairs.get(index);
        }
 else {
          currentPair=null;
        }
      }
 while (currentPair != null && ByteUtils.compare(ByteUtils.copy(prevPair.keyMd5,0,2 * ByteUtils.SIZE_OF_INT),ByteUtils.copy(currentPair.keyMd5,0,2 * ByteUtils.SIZE_OF_INT)) == 0);
      valueStream.flush();
      byte[] numBuf=new byte[1];
      numBuf[0]=(byte)tuples;
      datas[nodeId][chunk].write(numBuf);
      datas[nodeId][chunk].write(stream.toByteArray());
      positions[nodeId][chunk]+=1 + stream.toByteArray().length;
    }
  }
  logger.info("Closing all store files.");
  for (  Node node : cluster.getNodes()) {
    for (int chunk=0; chunk < numChunks * node.getNumberOfPartitions(); chunk++) {
      indexes[node.getId()][chunk].close();
      datas[node.getId()][chunk].close();
    }
  }
}
