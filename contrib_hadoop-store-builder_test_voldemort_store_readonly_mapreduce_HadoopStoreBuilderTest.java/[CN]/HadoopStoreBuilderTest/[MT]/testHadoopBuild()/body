{
  Map<String,String> values=new HashMap<String,String>();
  File testDir=TestUtils.createTempDir();
  File tempDir=new File(testDir,"temp"), tempDir2=new File(testDir,"temp2");
  File outputDir=new File(testDir,"output"), outputDir2=new File(testDir,"output2");
  File storeDir=TestUtils.createTempDir(testDir);
  for (int i=0; i < 200; i++)   values.put(Integer.toString(i),Integer.toBinaryString(i));
  File inputFile=File.createTempFile("input",".txt",testDir);
  inputFile.deleteOnExit();
  StringBuilder contents=new StringBuilder();
  for (  Map.Entry<String,String> entry : values.entrySet())   contents.append(entry.getKey() + "\t" + entry.getValue()+ "\n");
  FileUtils.writeStringToFile(inputFile,contents.toString());
  String storeName="test";
  SerializerDefinition serDef=new SerializerDefinition("string");
  Cluster cluster=ServerTestUtils.getLocalCluster(1);
  StoreDefinition def=new StoreDefinitionBuilder().setName(storeName).setType(ReadOnlyStorageConfiguration.TYPE_NAME).setKeySerializer(serDef).setValueSerializer(serDef).setRoutingPolicy(RoutingTier.CLIENT).setRoutingStrategyType(RoutingStrategyType.CONSISTENT_STRATEGY).setReplicationFactor(1).setPreferredReads(1).setRequiredReads(1).setPreferredWrites(1).setRequiredWrites(1).build();
  HadoopStoreBuilder builder=new HadoopStoreBuilder(new Configuration(),TextStoreMapper.class,TextInputFormat.class,cluster,def,64 * 1024,new Path(tempDir2.getAbsolutePath()),new Path(outputDir2.getAbsolutePath()),new Path(inputFile.getAbsolutePath()),CheckSumType.NONE);
  builder.build();
  builder=new HadoopStoreBuilder(new Configuration(),TextStoreMapper.class,TextInputFormat.class,cluster,def,64 * 1024,new Path(tempDir.getAbsolutePath()),new Path(outputDir.getAbsolutePath()),new Path(inputFile.getAbsolutePath()),CheckSumType.MD5);
  builder.build();
  File nodeFile=new File(outputDir,"node-0");
  File metadataFile=new File(nodeFile,".metadata");
  assertTrue(metadataFile.exists());
  ReadOnlyStorageMetadata metadata=new ReadOnlyStorageMetadata(metadataFile);
  assertEquals(metadata.get(ReadOnlyStorageMetadata.FORMAT),ReadOnlyStorageFormat.READONLY_V1.getCode());
  File checkSumFile=new File(nodeFile,"md5checkSum.txt");
  assertTrue(checkSumFile.exists());
  byte[] md5=new byte[16];
  DataInputStream in=new DataInputStream(new FileInputStream(checkSumFile));
  in.read(md5);
  in.close();
  byte[] checkSumBytes=CheckSumTests.calculateCheckSum(nodeFile.listFiles(),CheckSumType.MD5);
  assertEquals(0,ByteUtils.compare(checkSumBytes,md5));
  HdfsFetcher fetcher=new HdfsFetcher();
  File versionDir=new File(storeDir,"version-0");
  fetcher.fetch(nodeFile.getAbsolutePath(),versionDir.getAbsolutePath());
  assertTrue(versionDir.exists());
  @SuppressWarnings("unchecked") Serializer<Object> serializer=(Serializer<Object>)new DefaultSerializerFactory().getSerializer(serDef);
  Store<Object,Object,Object> store=SerializingStore.wrap(new ReadOnlyStorageEngine(storeName,new BinarySearchStrategy(),new RoutingStrategyFactory().updateRoutingStrategy(def,cluster),0,storeDir,1),serializer,serializer,serializer);
  for (  Map.Entry<String,String> entry : values.entrySet()) {
    List<Versioned<Object>> found=store.get(entry.getKey(),null);
    assertEquals("Incorrect number of results",1,found.size());
    assertEquals(entry.getValue(),found.get(0).getValue());
  }
}
