{
  int chunkId=ReadOnlyUtils.chunk(key.getBytes(),getNumChunks());
  initFileStreams(chunkId);
  this.indexFileStream[chunkId].write(key.getBytes(),0,key.getLength());
  this.indexFileSizeInBytes[chunkId]+=key.getLength();
  this.indexFileStream[chunkId].writeInt(this.position[chunkId]);
  this.indexFileSizeInBytes[chunkId]+=ByteUtils.SIZE_OF_INT;
  if (this.checkSumDigestIndex[chunkId] != null) {
    this.checkSumDigestIndex[chunkId].update(key.getBytes(),0,key.getLength());
    this.checkSumDigestIndex[chunkId].update(this.position[chunkId]);
  }
  short numTuples=0;
  ByteArrayOutputStream stream=new ByteArrayOutputStream();
  DataOutputStream valueStream=new DataOutputStream(stream);
  while (iterator.hasNext()) {
    BytesWritable writable=iterator.next();
    byte[] valueBytes=writable.getBytes();
    int offsetTillNow=0;
    int currentNodeId=ByteUtils.readInt(valueBytes,offsetTillNow);
    if (this.nodeId == -1) {
      this.nodeId=currentNodeId;
    }
 else     if (this.nodeId != currentNodeId) {
      throw new IllegalArgumentException("Should not get various nodeId shuffled to us! " + "First nodeId seen: " + this.nodeId + ", currentNodeId: "+ currentNodeId);
    }
    offsetTillNow+=ByteUtils.SIZE_OF_INT;
    int currentPartitionId=ByteUtils.readInt(valueBytes,offsetTillNow);
    if (this.partitionId == -1) {
      this.partitionId=currentPartitionId;
    }
 else     if (this.partitionId != currentPartitionId) {
      throw new IllegalArgumentException("Should not get various partitionId shuffled to us! " + "First partitionId seen: " + this.partitionId + ", currentPartitionId: "+ currentPartitionId);
    }
    offsetTillNow+=ByteUtils.SIZE_OF_INT;
    if (getSaveKeys()) {
      int currentReplicaType=(int)ByteUtils.readBytes(valueBytes,offsetTillNow,ByteUtils.SIZE_OF_BYTE);
      if (this.replicaType == -1) {
        this.replicaType=currentReplicaType;
      }
 else       if (this.replicaType != currentReplicaType) {
        throw new IllegalArgumentException("Should not get various replicaType shuffled to us! " + "First replicaType seen: " + this.replicaType + ", currentReplicaType: "+ currentReplicaType);
      }
      if (getBuildPrimaryReplicasOnly() && this.replicaType > 0) {
        throw new IllegalArgumentException("Should not get any replicaType > 0 shuffled to us" + " when buildPrimaryReplicasOnly mode is enabled!");
      }
      offsetTillNow+=ByteUtils.SIZE_OF_BYTE;
    }
    int valueLength=writable.getLength() - offsetTillNow;
    if (getSaveKeys()) {
      valueStream.write(valueBytes,offsetTillNow,valueLength);
    }
 else {
      valueStream.writeInt(valueLength);
      valueStream.write(valueBytes,offsetTillNow,valueLength);
    }
    numTuples++;
    if (!getSaveKeys() && numTuples > 1)     throw new VoldemortException("Duplicate keys detected for md5 sum " + ByteUtils.toHexString(ByteUtils.copy(key.getBytes(),0,key.getLength())));
  }
  if (numTuples < 0) {
    throw new VoldemortException("Found too many collisions: chunk " + chunkId + " has exceeded "+ Short.MAX_VALUE+ " collisions.");
  }
 else   if (numTuples > 1) {
    reporter.incrCounter(CollisionCounter.NUM_COLLISIONS,1);
    long numCollisions=reporter.getCounter(CollisionCounter.MAX_COLLISIONS).getCounter();
    if (numTuples > numCollisions) {
      reporter.incrCounter(CollisionCounter.MAX_COLLISIONS,numTuples - numCollisions);
    }
  }
  valueStream.flush();
  byte[] value=stream.toByteArray();
  if (getSaveKeys()) {
    this.valueFileStream[chunkId].writeShort(numTuples);
    this.valueFileSizeInBytes[chunkId]+=ByteUtils.SIZE_OF_SHORT;
    this.position[chunkId]+=ByteUtils.SIZE_OF_SHORT;
    if (this.checkSumDigestValue[chunkId] != null) {
      this.checkSumDigestValue[chunkId].update(numTuples);
    }
  }
  this.valueFileStream[chunkId].write(value);
  this.valueFileSizeInBytes[chunkId]+=value.length;
  this.position[chunkId]+=value.length;
  if (this.checkSumDigestValue[chunkId] != null) {
    this.checkSumDigestValue[chunkId].update(value);
  }
  if (this.position[chunkId] < 0)   throw new VoldemortException("Chunk overflow exception: chunk " + chunkId + " has exceeded "+ Integer.MAX_VALUE+ " bytes.");
}
