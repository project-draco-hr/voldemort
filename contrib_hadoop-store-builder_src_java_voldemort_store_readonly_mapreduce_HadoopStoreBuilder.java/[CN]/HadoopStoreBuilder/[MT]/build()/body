{
  try {
    Job job=new Job(config);
    job.getConfiguration().setInt("io.file.buffer.size",DEFAULT_BUFFER_SIZE);
    job.getConfiguration().set("cluster.xml",new ClusterMapper().writeCluster(cluster));
    job.getConfiguration().set("stores.xml",new StoreDefinitionsMapper().writeStoreList(Collections.singletonList(storeDef)));
    job.getConfiguration().set("final.output.dir",outputDir.toString());
    job.getConfiguration().set("checksum.type",CheckSum.toString(checkSumType));
    job.setPartitionerClass(HadoopStoreBuilderPartitioner.class);
    job.setMapperClass(mapperClass);
    job.setMapOutputKeyClass(BytesWritable.class);
    job.setMapOutputValueClass(BytesWritable.class);
    job.setReducerClass(HadoopStoreBuilderReducer.class);
    job.setInputFormatClass(inputFormatClass);
    job.setOutputFormatClass(SequenceFileOutputFormat.class);
    job.setOutputKeyClass(BytesWritable.class);
    job.setOutputValueClass(BytesWritable.class);
    job.setJarByClass(getClass());
    FileInputFormat.setInputPaths(job,inputPath);
    FileOutputFormat.setOutputPath(job,tempDir);
    FileSystem outputFs=outputDir.getFileSystem(job.getConfiguration());
    if (outputFs.exists(outputDir)) {
      throw new IOException("Final output directory already exists.");
    }
    FileSystem tempFs=tempDir.getFileSystem(job.getConfiguration());
    tempFs.delete(tempDir,true);
    long size=sizeOfPath(tempFs,inputPath);
    int numChunks=Math.max((int)(storeDef.getReplicationFactor() * size / cluster.getNumberOfNodes() / chunkSizeBytes),1);
    logger.info("Data size = " + size + ", replication factor = "+ storeDef.getReplicationFactor()+ ", numNodes = "+ cluster.getNumberOfNodes()+ ", chunk size = "+ chunkSizeBytes+ ",  num.chunks = "+ numChunks);
    job.getConfiguration().setInt("num.chunks",numChunks);
    int numReduces=cluster.getNumberOfNodes() * numChunks;
    job.setNumReduceTasks(numReduces);
    logger.info("Number of reduces: " + numReduces);
    logger.info("Building store...");
    job.waitForCompletion(true);
    ReadOnlyStorageMetadata metadata=new ReadOnlyStorageMetadata();
    metadata.add(ReadOnlyStorageMetadata.FORMAT,ReadOnlyStorageFormat.READONLY_V1.getCode());
    for (    Node node : cluster.getNodes()) {
      Path nodePath=new Path(outputDir.toString(),"node-" + node.getId());
      if (!outputFs.exists(nodePath)) {
        outputFs.mkdirs(nodePath);
      }
      FSDataOutputStream metadataStream=outputFs.create(new Path(nodePath,".metadata"));
      metadataStream.write(metadata.toJsonString().getBytes());
      metadataStream.flush();
      metadataStream.close();
    }
    if (checkSumType != CheckSumType.NONE) {
      FileStatus[] nodes=outputFs.listStatus(outputDir);
      CheckSum checkSumGenerator=CheckSum.getInstance(this.checkSumType);
      if (checkSumGenerator == null) {
        throw new VoldemortException("Could not generate checksum digests");
      }
      for (      FileStatus node : nodes) {
        if (node.isDir()) {
          FileStatus[] storeFiles=outputFs.listStatus(node.getPath(),new PathFilter(){
            public boolean accept(            Path arg0){
              if (arg0.getName().endsWith("checksum") && !arg0.getName().startsWith(".")) {
                return true;
              }
              return false;
            }
          }
);
          if (storeFiles != null) {
            Arrays.sort(storeFiles,new IndexFileLastComparator());
            for (            FileStatus file : storeFiles) {
              FSDataInputStream input=outputFs.open(file.getPath());
              byte fileCheckSum[]=new byte[CheckSum.checkSumLength(this.checkSumType)];
              input.read(fileCheckSum);
              checkSumGenerator.update(fileCheckSum);
              outputFs.delete(file.getPath(),true);
            }
            FSDataOutputStream checkSumStream=outputFs.create(new Path(node.getPath(),CheckSum.toString(checkSumType) + "checkSum.txt"));
            checkSumStream.write(checkSumGenerator.getCheckSum());
            checkSumStream.flush();
            checkSumStream.close();
          }
        }
      }
    }
  }
 catch (  Exception e) {
    throw new VoldemortException(e);
  }
}
