{
  if (!metadataStore.getServerState().equals(MetadataStore.VoldemortState.NORMAL_SERVER)) {
    logger.error("Cannot run slop pusher job since cluster is rebalancing");
    return;
  }
synchronized (lock) {
    Date startTime=new Date();
    logger.info("Started streaming slop pusher job at " + startTime);
    SlopStorageEngine slopStorageEngine=storeRepo.getSlopStore();
    ClosableIterator<Pair<ByteArray,Versioned<Slop>>> iterator=null;
    ConcurrentHashMap<Integer,Long> attemptedByNode=new ConcurrentHashMap<Integer,Long>(cluster.getNumberOfNodes());
    ConcurrentHashMap<Integer,Long> succeededByNode=new ConcurrentHashMap<Integer,Long>(cluster.getNumberOfNodes());
    AtomicLong slopsPushed=new AtomicLong(0);
    AtomicLong attemptedPushes=new AtomicLong(0);
    for (    Node node : cluster.getNodes()) {
      attemptedByNode.put(node.getId(),0L);
      succeededByNode.put(node.getId(),0L);
    }
    try {
      StorageEngine<ByteArray,Slop,byte[]> slopStore=slopStorageEngine.asSlopStore();
      iterator=slopStore.entries();
      while (iterator.hasNext()) {
        Pair<ByteArray,Versioned<Slop>> keyAndVal;
        try {
          keyAndVal=iterator.next();
          Versioned<Slop> versioned=keyAndVal.getSecond();
          int nodeId=versioned.getValue().getNodeId();
          Node node=cluster.getNodeById(nodeId);
          attemptedPushes.incrementAndGet();
          Long attempted=attemptedByNode.get(nodeId);
          attemptedByNode.put(nodeId,attempted + 1L);
          if (attemptedPushes.get() % 10000 == 0)           logger.info("Attempted pushing " + attemptedPushes + " slops");
          logger.info("On slop = " + versioned.getValue().getNodeId() + " => "+ new String(versioned.getValue().getKey().get()));
          if (failureDetector.isAvailable(node)) {
            SynchronousQueue<Versioned<Slop>> slopQueue=slopQueues.get(nodeId);
            if (slopQueue == null) {
              slopQueue=new SynchronousQueue<Versioned<Slop>>();
              slopQueues.put(nodeId,slopQueue);
              consumerResults.add(consumerExecutor.submit(new SlopConsumer(nodeId,slopQueue,slopStorageEngine,succeededByNode.get(nodeId),slopsPushed)));
            }
            slopQueue.offer(versioned,1,TimeUnit.SECONDS);
            readThrottler.maybeThrottle(nBytesRead(keyAndVal));
          }
 else {
            logger.info(node + " declared down, won't push slop");
          }
        }
 catch (        RejectedExecutionException e) {
          throw new VoldemortException("Ran out of threads in executor",e);
        }
      }
      logger.log(attemptedPushes.get() > 0 ? Level.INFO : Level.DEBUG,"Attempted " + attemptedPushes + " hinted handoff pushes of which "+ slopsPushed+ " succeeded.");
      Map<Integer,Long> outstanding=Maps.newHashMapWithExpectedSize(cluster.getNumberOfNodes());
      for (      int nodeId : succeededByNode.keySet()) {
        outstanding.put(nodeId,attemptedByNode.get(nodeId) - succeededByNode.get(nodeId));
      }
      slopStorageEngine.resetStats(outstanding);
    }
 catch (    InterruptedException e) {
    }
catch (    Exception e) {
      logger.error(e,e);
    }
 finally {
      try {
        if (iterator != null)         iterator.close();
      }
 catch (      Exception e) {
        logger.warn("Failed to close iterator cleanly as database might be closed",e);
      }
      for (      SynchronousQueue<Versioned<Slop>> slopQueue : slopQueues.values()) {
        try {
          slopQueue.offer(END,1,TimeUnit.SECONDS);
        }
 catch (        InterruptedException e) {
          logger.error("Error putting poison pill",e);
        }
      }
      for (      Future result : consumerResults) {
        try {
          result.get();
        }
 catch (        Exception e) {
          logger.error("Exception in consumer",e);
        }
      }
      consumerResults.clear();
      slopQueues.clear();
    }
    logger.info("Completed streaming slop pusher job which started at " + startTime);
  }
}
