{
  loadMetadata();
  if (metadataStore.getServerStateUnlocked().equals(MetadataStore.VoldemortState.REBALANCING_MASTER_SERVER)) {
    logger.error("Cannot run slop pusher job since Voldemort server is rebalancing");
    return;
  }
  boolean terminatedEarly=false;
  Date startTime=new Date();
  logger.info("Started streaming slop pusher job at " + startTime);
  SlopStorageEngine slopStorageEngine=storeRepo.getSlopStore();
  ClosableIterator<Pair<ByteArray,Versioned<Slop>>> iterator=null;
  if (adminClient == null) {
    adminClient=new AdminClient(cluster,new AdminClientConfig().setMaxConnectionsPerNode(1));
  }
  if (voldemortConfig.getSlopZonesDownToTerminate() > 0) {
    zoneMapping.clear();
    for (    Node n : cluster.getNodes()) {
      if (failureDetector.isAvailable(n)) {
        Set<Integer> nodes=zoneMapping.get(n.getZoneId());
        if (nodes == null) {
          nodes=Sets.newHashSet();
          zoneMapping.put(n.getZoneId(),nodes);
        }
        nodes.add(n.getId());
      }
    }
    int zonesDown=0;
    for (    Zone zone : cluster.getZones()) {
      if (zoneMapping.get(zone.getId()) == null || zoneMapping.get(zone.getId()).size() == 0)       zonesDown++;
    }
    if (voldemortConfig.getSlopZonesDownToTerminate() <= zoneMapping.size() && zonesDown >= voldemortConfig.getSlopZonesDownToTerminate()) {
      logger.info("Completed streaming slop pusher job at " + startTime + " early because "+ zonesDown+ " zones are down");
      stopAdminClient();
      return;
    }
  }
  AtomicLong attemptedPushes=new AtomicLong(0);
  for (  Node node : cluster.getNodes()) {
    attemptedByNode.put(node.getId(),0L);
    succeededByNode.put(node.getId(),0L);
  }
  Set<String> storeNames=StoreDefinitionUtils.getStoreNamesSet(metadataStore.getStoreDefList());
  acquireRepairPermit();
  try {
    StorageEngine<ByteArray,Slop,byte[]> slopStore=slopStorageEngine.asSlopStore();
    iterator=slopStore.entries();
    while (iterator.hasNext()) {
      Pair<ByteArray,Versioned<Slop>> keyAndVal;
      try {
        keyAndVal=iterator.next();
        Versioned<Slop> versioned=keyAndVal.getSecond();
        if (this.streamStats != null) {
          this.streamStats.reportStreamingSlopScan();
        }
        int nodeId=versioned.getValue().getNodeId();
        if (isSlopDead(cluster,storeNames,versioned.getValue())) {
          handleDeadSlop(slopStorageEngine,keyAndVal);
          continue;
        }
        Node node=cluster.getNodeById(nodeId);
        attemptedPushes.incrementAndGet();
        Long attempted=attemptedByNode.get(nodeId);
        attemptedByNode.put(nodeId,attempted + 1L);
        if (attemptedPushes.get() % 10000 == 0)         logger.info("Attempted pushing " + attemptedPushes + " slops");
        if (logger.isTraceEnabled())         logger.trace("Pushing slop for " + versioned.getValue().getNodeId() + " and store  "+ versioned.getValue().getStoreName()+ " of key: "+ versioned.getValue().getKey());
        if (failureDetector.isAvailable(node)) {
          SynchronousQueue<Versioned<Slop>> slopQueue=slopQueues.get(nodeId);
          if (slopQueue == null) {
            slopQueue=new SynchronousQueue<Versioned<Slop>>();
            slopQueues.put(nodeId,slopQueue);
            consumerResults.add(consumerExecutor.submit(new SlopConsumer(nodeId,slopQueue,slopStorageEngine)));
          }
          boolean offered=slopQueue.offer(versioned,voldemortConfig.getClientRoutingTimeoutMs(),TimeUnit.MILLISECONDS);
          if (!offered) {
            if (logger.isDebugEnabled())             logger.debug("No consumer appeared for slop in " + voldemortConfig.getClientConnectionTimeoutMs() + " ms");
          }
          readThrottler.maybeThrottle(nBytesRead(keyAndVal));
        }
 else {
          logger.trace(node + " declared down, won't push slop");
        }
      }
 catch (      RejectedExecutionException e) {
        throw new VoldemortException("Ran out of threads in executor",e);
      }
    }
  }
 catch (  InterruptedException e) {
    logger.warn("Interrupted exception",e);
    terminatedEarly=true;
  }
catch (  Exception e) {
    logger.error(e,e);
    terminatedEarly=true;
  }
 finally {
    try {
      if (iterator != null)       iterator.close();
    }
 catch (    Exception e) {
      logger.warn("Failed to close iterator cleanly as database might be closed",e);
    }
    for (    SynchronousQueue<Versioned<Slop>> slopQueue : slopQueues.values()) {
      try {
        slopQueue.put(END);
      }
 catch (      InterruptedException e) {
        logger.warn("Error putting poison pill",e);
      }
    }
    for (    Future result : consumerResults) {
      try {
        result.get();
      }
 catch (      Exception e) {
        logger.warn("Exception in consumer",e);
      }
    }
    if (!terminatedEarly) {
      Map<Integer,Long> outstanding=Maps.newHashMapWithExpectedSize(cluster.getNumberOfNodes());
      for (      int nodeId : succeededByNode.keySet()) {
        logger.info("Slops to node " + nodeId + " - Succeeded - "+ succeededByNode.get(nodeId)+ " - Attempted - "+ attemptedByNode.get(nodeId));
        outstanding.put(nodeId,attemptedByNode.get(nodeId) - succeededByNode.get(nodeId));
      }
      slopStorageEngine.resetStats(outstanding);
      logger.info("Completed streaming slop pusher job which started at " + startTime);
    }
 else {
      for (      int nodeId : succeededByNode.keySet()) {
        logger.info("Slops to node " + nodeId + " - Succeeded - "+ succeededByNode.get(nodeId)+ " - Attempted - "+ attemptedByNode.get(nodeId));
      }
      logger.info("Completed early streaming slop pusher job which started at " + startTime);
    }
    consumerResults.clear();
    slopQueues.clear();
    stopAdminClient();
    this.repairPermits.release(this.getClass().getCanonicalName());
  }
}
