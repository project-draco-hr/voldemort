{
  JobConf conf=new JobConf();
  HadoopUtils.copyInAllProps(_props,conf);
  Cluster cluster=HadoopUtils.readCluster(_props.get("voldemort.cluster.file"),conf);
  final String storeName=_props.get("voldemort.store.name");
  final Path inputDir=new Path(_props.get("input.path"));
  ExecutorService executors=Executors.newFixedThreadPool(cluster.getNumberOfNodes());
  final Semaphore semaphore=new Semaphore(0,false);
  final AtomicInteger countSuccess=new AtomicInteger(0);
  final Map<Integer,Boolean> succeeded=new HashMap<Integer,Boolean>();
  final String destinationDir=_props.get("dest.path");
  final String sourceHost=_props.getString("src.host","localhost");
  for (  final Node node : cluster.getNodes()) {
    executors.execute(new Runnable(){
      public void run(){
        int id=node.getId();
        String indexFile=inputDir + "/" + storeName+ ".index"+ "_"+ Integer.toString(id);
        String dataFile=inputDir + "/" + storeName+ ".data"+ "_"+ Integer.toString(id);
        String host=node.getHost();
        try {
          succeeded.put(node.getId(),true);
          countSuccess.incrementAndGet();
        }
 catch (        Exception e) {
          error("copy to Remote node failed for node:" + node.getId(),e);
        }
        semaphore.release();
      }
    }
);
  }
  semaphore.acquire(cluster.getNumberOfNodes());
  try {
    if (countSuccess.get() == cluster.getNumberOfNodes() || _props.getBoolean("swap.partial.index",false)) {
      int counter=0;
      for (      Node node : cluster.getNodes()) {
        if (succeeded.get(node.getId())) {
          VoldemortSwapperUtils.doSwap(storeName,node,destinationDir);
          counter++;
        }
      }
      info(counter + " node out of " + cluster.getNumberOfNodes()+ " refreshed with fresh index/data for store '"+ storeName+ "'");
    }
 else {
      error("Failed to copy Index Files for the entire cluster.");
    }
  }
  finally {
    executors.shutdown();
  }
}
